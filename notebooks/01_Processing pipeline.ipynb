{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.io \n",
    "import matplotlib.pyplot as plt \n",
    "import os, sys\n",
    "import pickle\n",
    "import pandas as pd \n",
    "from skimage.registration import phase_cross_correlation\n",
    "import cv2 \n",
    "import itertools\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import path \n",
    "module_path = str(Path.cwd().parents[0])\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processed image folder is already there\nNo Info csv file\n"
     ]
    }
   ],
   "source": [
    "csv_file = data_meta / 'all_info.csv'\n",
    "csv_exist = csv_file.is_file()\n",
    "\n",
    "# Create directory if not existL\n",
    "try:\n",
    "    data_processed.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Processed image folder is already there\")\n",
    "else:\n",
    "    print(\"Processed image folder was created\")\n",
    "    \n",
    "if csv_exist:\n",
    "    print('Info csv file already exists')\n",
    "else:\n",
    "    print('No Info csv file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get folder information\n",
    "\n",
    "Read information to pandas dataframe of the image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "channel2marker = {\n",
    "    '2seg':\n",
    "    {\n",
    "        'CH1' : 'DAPI', \n",
    "        'CH4' : 'WGA',\n",
    "        'CH3' : 'Phalloidin'\n",
    "    },\n",
    "    'Concanavadin A':\n",
    "    {\n",
    "        'CH1' : 'DAPI', \n",
    "        'CH2' : 'Concanavadin A'\n",
    "    },\n",
    "    'CycD1':\n",
    "    {\n",
    "        'CH1' : 'DAPI', \n",
    "        'CH4' : 'Cyclin D1',\n",
    "        'CH3' : 'APC'\n",
    "    }\n",
    "    ,'CycE':\n",
    "    {\n",
    "        'CH1' : 'DAPI', \n",
    "        'CH4' : 'WNT-1',\n",
    "        'CH3' : 'EMMPRIN',\n",
    "        'CH2' : 'Cyclin E'\n",
    "    }\n",
    "    ,'DKK1':\n",
    "    {\n",
    "        'CH1' : 'DAPI', \n",
    "        'CH4' : 'DKK1',\n",
    "        'CH2' : 'Non-phospho-B-catenin'\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_info(img_folder, name_dict = channel2marker, save=False):\n",
    "    '''Function returns the info from folder containing multi-cycle staigning on cell\n",
    "    \n",
    "    Args: \n",
    "        img_folder (str) : imgage folder path to get information\n",
    "        name_dict (dict) : three level dictionnary mapping cycle -> channel -> marker name\n",
    "        \n",
    "    Returns:\n",
    "        pandas dataframe with information\n",
    "    '''\n",
    "    conditions = []\n",
    "    cycles = []\n",
    "    z_stacks = []\n",
    "    channels = []\n",
    "    images_path = []\n",
    "    markers = []\n",
    "\n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(img_folder):\n",
    "        for name in sorted(filenames):\n",
    "            if 'aftBleach' not in dirpath and 'Fw' in dirpath:            \n",
    "                if 'tif' in name and 'Overlay' not in name and 'FF_' not in name:\n",
    "                    # Get information from image name \n",
    "                    condition = dirpath[-3:]\n",
    "                    z_stack = '_'.join(name.split('_')[2:3])\n",
    "                    channel = name.split('_')[-1].split('.')[0]\n",
    "                    cycle = dirpath.split('\\\\')[-1].split('_')[1]\n",
    "\n",
    "                    if z_stack == \"\":\n",
    "                        continue\n",
    "                        \n",
    "                    markers.append(name_dict[cycle][channel])\n",
    "\n",
    "                    cycles.append(cycle)\n",
    "                    conditions.append(condition)\n",
    "                    z_stacks.append(int(z_stack[1:]))\n",
    "                    channels.append(channel)\n",
    "                    images_path.append(os.path.join(dirpath,name))\n",
    "\n",
    "    info = {'Cycle':cycles, 'Condition':conditions, 'Z_stack': z_stacks, 'Channel': channels, 'Marker': markers,'Path': images_path}\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    \n",
    "    if save == True:\n",
    "        df.to_csv('info.csv', index=False)\n",
    "        \n",
    "    df.Z_stack = pd.to_numeric(df.Z_stack)\n",
    "    \n",
    "    df['Path_corrected'] = ''\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created pandas dataframe\n"
     ]
    }
   ],
   "source": [
    "if not csv_exist:\n",
    "    df = get_info(data_raw)\n",
    "    print('Created pandas dataframe')\n",
    "else:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print('Imported pandas dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image background subtraction\n",
    "\n",
    "Image shadding correction using background subtration of gaussian blurr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_condition_channel(df, cycle, condition, channel):\n",
    "    '''Function returns dataframe of specified channel image based on condition from input dataframe\n",
    "    \n",
    "    Args: \n",
    "        df (pd DataFrame) : info dataframe for all images \n",
    "        condition (str) : condition name\n",
    "        \n",
    "    Returns:\n",
    "        pandas dataframe with information\n",
    "    '''\n",
    "    return df[(df['Condition'] == condition) & (df['Channel'] == channel) & (df['Cycle'] == cycle)]\n",
    "\n",
    "def background_correction(df, filtersize = 257, sigma = 128, folder = data_processed, save=False, show=False):\n",
    "    '''Function to perform background substraction for image using gaussian blurr of original image \n",
    "    \n",
    "    Args: \n",
    "        df (pd DataFrame) : info dataframe for all images \n",
    "        filtersize (int) : filter size of gaussian kernel\n",
    "        sigma (int) : sigma of guassian blurr\n",
    "        folder (str) : folder to save corrected images\n",
    "        save (bool) : bool to save the image\n",
    "        show (bool) : bool to show corrected image and gaussian blur of original image\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    # Loop through the rows of the dataframe\n",
    "    for row in df.itertuples():\n",
    "        # Read image\n",
    "        img = skimage.io.imread(row.Path)\n",
    "        \n",
    "        # Define saving filename for corrected image\n",
    "        filename = '_'.join([row.Condition, str(row.Z_stack), row.Cycle, row.Marker])\n",
    "        path = os.path.join(folder,filename+'.tiff')\n",
    "        \n",
    "        # If marker is Phalloidin no correction needed for better segmentation:\n",
    "        if row.Marker == 'Phalloidin':\n",
    "            if save:\n",
    "                cv2.imwrite(path, img) \n",
    "                df.at[row.Index,'Path_corrected'] = path\n",
    "            continue\n",
    "        \n",
    "        # Background substraction using gaussian blur channel\n",
    "        gaussianImg = cv2.GaussianBlur(img, (filtersize, filtersize), sigma)\n",
    "        img_corrected = cv2.subtract(img,gaussianImg)\n",
    "        \n",
    "        # Save image\n",
    "        if save:\n",
    "            cv2.imwrite(path, img_corrected) \n",
    "            df.at[row.Index,'Path_corrected'] = path\n",
    "        \n",
    "        # Show correction\n",
    "        if show:\n",
    "            fig = plt.figure(figsize=(25, 7))\n",
    "            ax1 = plt.subplot(1, 3, 1)\n",
    "            ax2 = plt.subplot(1, 3, 2)\n",
    "            ax3 = plt.subplot(1, 3, 3)\n",
    "\n",
    "            ax1.imshow(img, alpha=1)\n",
    "            ax1.set_axis_off()\n",
    "            ax1.set_title('Original Image')\n",
    "\n",
    "            ax2.imshow(img_corrected, alpha=1)\n",
    "            ax2.set_axis_off()\n",
    "            ax2.set_title('Corrected image')\n",
    "\n",
    "            ax3.imshow(gaussianImg, cmap='gray', alpha=1)\n",
    "            ax3.set_axis_off()\n",
    "            ax3.set_title('Background image')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created images with background correction\n"
     ]
    }
   ],
   "source": [
    "if not csv_file.is_file():\n",
    "    background_correction(df, save=True)\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print('Created images with background correction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image registration\n",
    "\n",
    "Image registration using the DAPI channel across images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shift_within_cycle(df):\n",
    "    '''Function to get shift within each cycle of the DAPI channel \n",
    "    \n",
    "    Args: \n",
    "        df (pd DataFrame) : info dataframe for images \n",
    "        \n",
    "    Returns:\n",
    "        print shift values between each level\n",
    "    '''\n",
    "    # Get elements of DAPI channel\n",
    "    df = df[df['Marker'] == 'DAPI']\n",
    "    \n",
    "    # Loop through condition\n",
    "    for condition in df.Condition.unique():\n",
    "        for cycle in df.Cycle.unique():\n",
    "            # Read the cycle info and z level of 1 for reference dapi channel\n",
    "            temp = df[(df.Cycle == cycle) & (df.Condition == condition)]\n",
    "            reference = temp[temp.Z_stack == 1]\n",
    "            reference_dapi = skimage.io.imread(reference.Path_corrected.item())\n",
    "\n",
    "            # number of z level in this cycle\n",
    "            n_channel = temp.Z_stack.max()+1\n",
    "            \n",
    "            # Get shift between z level \n",
    "            for i in range(2, n_channel):\n",
    "                img_dapi = skimage.io.imread(temp[temp.Z_stack == i].Path_corrected.item())\n",
    "                shift, error, diffphase = phase_cross_correlation(reference_dapi, img_dapi)\n",
    "                print(f\"For {cycle} detected subpixel offset ({shift[0]}, {shift[1]}) between level 1 and level {i} stack for {condition}\")\n",
    "            \n",
    "def get_shift_between_cycle(df):\n",
    "    '''Function to get shift within each cycle for the DAPI channel\n",
    "    \n",
    "    Args: \n",
    "        df (pd DataFrame) : info dataframe for images in dapi channel accross cycle\n",
    "        \n",
    "    Returns:\n",
    "        shift dictionnary\n",
    "    '''\n",
    "    # Get elements of DAPI channel\n",
    "    df = df[df['Marker'] == 'DAPI']\n",
    "    \n",
    "    # Get shift between cycle\n",
    "    cycles = df.Cycle.unique()\n",
    "    conditions = df.Condition.unique()\n",
    "    shift_dict = {}\n",
    "    for condition in conditions:\n",
    "        # Get subset of specific condition\n",
    "        df_subset = df[df.Condition == condition]\n",
    "        \n",
    "        # Get reference cycle\n",
    "        temp = df_subset[df_subset.Cycle == cycles[0]]  \n",
    "        reference = temp[temp.Z_stack == 1]\n",
    "        reference_dapi = skimage.io.imread(reference.Path_corrected.item())\n",
    "    \n",
    "        # Define shift dictionnary\n",
    "        shift_dict[condition] = {}\n",
    "\n",
    "        # Max shift accross all cycle:\n",
    "        max_shift_x = 0\n",
    "        min_shift_x = 0\n",
    "        max_shift_y = 0\n",
    "        min_shift_y = 0\n",
    "\n",
    "        for cycle in cycles[1:]:\n",
    "            temp = df_subset[df.Cycle == cycle]    \n",
    "            img_dapi = skimage.io.imread(temp[temp.Z_stack == 1].Path_corrected.item())\n",
    "\n",
    "            # Get image shift y and x and save to shift_dict\n",
    "            shift, _, _ = phase_cross_correlation(reference_dapi, img_dapi) # Shift vector required to register moving images with reference images. Axis orderingis constitent with Y,X\n",
    "            print(f\"For {cycle} detected subpixel offset ({shift[0]}, {shift[1]}) compared to {cycles[0]} for {condition}\")\n",
    "            shift_y, shift_x = shift[0], shift[1]\n",
    "            shift_dict[condition][cycle] = {'shift_x':shift_x, 'shift_y':shift_y}\n",
    "\n",
    "            # Update max shift\n",
    "            max_shift_x = shift_x if shift_x > max_shift_x else max_shift_x\n",
    "            min_shift_x = shift_x if shift_x < min_shift_x else min_shift_x\n",
    "            max_shift_y = shift_y if shift_y > max_shift_y else max_shift_y\n",
    "            min_shift_y = shift_y if shift_y < min_shift_y else min_shift_y\n",
    "\n",
    "        max_shift_x = int(max_shift_x)\n",
    "        min_shift_x = int(min_shift_x)\n",
    "        max_shift_y = int(max_shift_y)\n",
    "        min_shift_y = int(min_shift_y)\n",
    "\n",
    "        shift_dict[condition]['max'] = {'max_shift_x':max_shift_x, 'min_shift_x':min_shift_x, 'max_shift_y':max_shift_y, 'min_shift_y':min_shift_y}\n",
    "\n",
    "    return shift_dict\n",
    "\n",
    "def shift_crop(df, shift_dict, save = True):\n",
    "    '''Function to shift and crop image based on shift_dict of pixels\n",
    "    \n",
    "    Args: \n",
    "        df (pd DataFrame) : info dataframe for images \n",
    "        shift_dict (dict) : shfit dictionnary between each cycle by condition\n",
    "        save (bool) : bool to save the images\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    # Iterate over condition\n",
    "    for condition in df.Condition.unique():\n",
    "        shift_dict_subset = shift_dict[condition]\n",
    "        \n",
    "        # Get max shift values\n",
    "        max_shift_x = shift_dict_subset['max']['max_shift_x']\n",
    "        min_shift_x = shift_dict_subset['max']['min_shift_x']\n",
    "        max_shift_y = shift_dict_subset['max']['max_shift_y']\n",
    "        min_shift_y = shift_dict_subset['max']['min_shift_y']\n",
    "    \n",
    "        # Get dataframe subset corresponding to condition \n",
    "        df_subset = df[df.Condition == condition]\n",
    "        \n",
    "        # iterate over rows:\n",
    "        for row in df_subset.itertuples():\n",
    "            img = skimage.io.imread(row.Path_corrected)\n",
    "            condition = row.Condition\n",
    "\n",
    "            # If not in shift dict then reference\n",
    "            if row.Cycle not in shift_dict_subset.keys():\n",
    "                # Crop image\n",
    "                res_cropped = img[max_shift_y: min_shift_y, max_shift_x:min_shift_x]\n",
    "                \n",
    "            else:\n",
    "                # Aplly shift \n",
    "                shift_x, shift_y = shift_dict_subset[row.Cycle]['shift_x'], shift_dict_subset[row.Cycle]['shift_y']\n",
    "                rows,cols = img.shape\n",
    "                M = np.float32([[1,0,shift_x],[0,1,shift_y]])\n",
    "                res = cv2.warpAffine(img, M, (cols, rows)) \n",
    "\n",
    "                # Crop image\n",
    "                res_cropped = res[max_shift_y: min_shift_y, max_shift_x:min_shift_x]\n",
    "                \n",
    "            if save: \n",
    "                cv2.imwrite(row.Path_corrected, res_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For 2seg detected subpixel offset (0.0, 0.0) between level 1 and level 2 stack for Fw1\n",
      "For 2seg detected subpixel offset (0.0, 0.0) between level 1 and level 3 stack for Fw1\n",
      "For 2seg detected subpixel offset (0.0, 0.0) between level 1 and level 4 stack for Fw1\n",
      "For Concanavadin A detected subpixel offset (0.0, 0.0) between level 1 and level 2 stack for Fw1\n",
      "For Concanavadin A detected subpixel offset (0.0, 0.0) between level 1 and level 3 stack for Fw1\n",
      "For Concanavadin A detected subpixel offset (0.0, 0.0) between level 1 and level 4 stack for Fw1\n",
      "For Concanavadin A detected subpixel offset (-2.0, 1.0) between level 1 and level 5 stack for Fw1\n",
      "For Concanavadin A detected subpixel offset (-2.0, 1.0) between level 1 and level 6 stack for Fw1\n",
      "For CycD1 detected subpixel offset (0.0, 0.0) between level 1 and level 2 stack for Fw1\n",
      "For CycD1 detected subpixel offset (0.0, 0.0) between level 1 and level 3 stack for Fw1\n",
      "For CycD1 detected subpixel offset (0.0, 0.0) between level 1 and level 4 stack for Fw1\n",
      "For CycE detected subpixel offset (0.0, 0.0) between level 1 and level 2 stack for Fw1\n",
      "For CycE detected subpixel offset (0.0, 0.0) between level 1 and level 3 stack for Fw1\n",
      "For CycE detected subpixel offset (0.0, 0.0) between level 1 and level 4 stack for Fw1\n",
      "For DKK1 detected subpixel offset (0.0, 0.0) between level 1 and level 2 stack for Fw1\n",
      "For DKK1 detected subpixel offset (0.0, 0.0) between level 1 and level 3 stack for Fw1\n",
      "For DKK1 detected subpixel offset (0.0, 0.0) between level 1 and level 4 stack for Fw1\n",
      "For DKK1 detected subpixel offset (0.0, 0.0) between level 1 and level 5 stack for Fw1\n",
      "For DKK1 detected subpixel offset (0.0, 0.0) between level 1 and level 6 stack for Fw1\n",
      "For 2seg detected subpixel offset (0.0, 0.0) between level 1 and level 2 stack for Fw2\n",
      "For 2seg detected subpixel offset (0.0, 0.0) between level 1 and level 3 stack for Fw2\n",
      "For 2seg detected subpixel offset (0.0, 0.0) between level 1 and level 4 stack for Fw2\n",
      "For 2seg detected subpixel offset (0.0, 1.0) between level 1 and level 5 stack for Fw2\n",
      "For 2seg detected subpixel offset (0.0, 0.0) between level 1 and level 6 stack for Fw2\n",
      "For 2seg detected subpixel offset (0.0, 0.0) between level 1 and level 7 stack for Fw2\n",
      "For 2seg detected subpixel offset (0.0, 0.0) between level 1 and level 8 stack for Fw2\n",
      "For Concanavadin A detected subpixel offset (0.0, 0.0) between level 1 and level 2 stack for Fw2\n",
      "For Concanavadin A detected subpixel offset (0.0, 0.0) between level 1 and level 3 stack for Fw2\n",
      "For Concanavadin A detected subpixel offset (0.0, 0.0) between level 1 and level 4 stack for Fw2\n",
      "For CycD1 detected subpixel offset (0.0, 0.0) between level 1 and level 2 stack for Fw2\n",
      "For CycD1 detected subpixel offset (0.0, 0.0) between level 1 and level 3 stack for Fw2\n",
      "For CycD1 detected subpixel offset (0.0, 0.0) between level 1 and level 4 stack for Fw2\n",
      "For CycD1 detected subpixel offset (0.0, 0.0) between level 1 and level 5 stack for Fw2\n",
      "For CycD1 detected subpixel offset (0.0, 0.0) between level 1 and level 6 stack for Fw2\n",
      "For CycE detected subpixel offset (0.0, 0.0) between level 1 and level 2 stack for Fw2\n",
      "For CycE detected subpixel offset (0.0, 0.0) between level 1 and level 3 stack for Fw2\n",
      "For CycE detected subpixel offset (0.0, 0.0) between level 1 and level 4 stack for Fw2\n",
      "For DKK1 detected subpixel offset (0.0, 1.0) between level 1 and level 2 stack for Fw2\n",
      "For DKK1 detected subpixel offset (0.0, 0.0) between level 1 and level 3 stack for Fw2\n",
      "For DKK1 detected subpixel offset (0.0, 0.0) between level 1 and level 4 stack for Fw2\n",
      "For DKK1 detected subpixel offset (0.0, 0.0) between level 1 and level 5 stack for Fw2\n",
      "For DKK1 detected subpixel offset (0.0, 0.0) between level 1 and level 6 stack for Fw2\n",
      "For DKK1 detected subpixel offset (0.0, 0.0) between level 1 and level 7 stack for Fw2\n",
      "For DKK1 detected subpixel offset (0.0, 0.0) between level 1 and level 8 stack for Fw2\n",
      "For 2seg detected subpixel offset (0.0, 0.0) between level 1 and level 2 stack for Fw3\n",
      "For 2seg detected subpixel offset (0.0, 0.0) between level 1 and level 3 stack for Fw3\n",
      "For 2seg detected subpixel offset (0.0, 0.0) between level 1 and level 4 stack for Fw3\n",
      "For 2seg detected subpixel offset (0.0, 0.0) between level 1 and level 5 stack for Fw3\n",
      "For 2seg detected subpixel offset (0.0, 0.0) between level 1 and level 6 stack for Fw3\n",
      "For 2seg detected subpixel offset (0.0, 0.0) between level 1 and level 7 stack for Fw3\n",
      "For 2seg detected subpixel offset (0.0, 0.0) between level 1 and level 8 stack for Fw3\n",
      "For Concanavadin A detected subpixel offset (0.0, 0.0) between level 1 and level 2 stack for Fw3\n",
      "For Concanavadin A detected subpixel offset (0.0, 0.0) between level 1 and level 3 stack for Fw3\n",
      "For Concanavadin A detected subpixel offset (0.0, 0.0) between level 1 and level 4 stack for Fw3\n",
      "For Concanavadin A detected subpixel offset (0.0, 0.0) between level 1 and level 5 stack for Fw3\n",
      "For Concanavadin A detected subpixel offset (0.0, 0.0) between level 1 and level 6 stack for Fw3\n",
      "For CycD1 detected subpixel offset (0.0, 0.0) between level 1 and level 2 stack for Fw3\n",
      "For CycD1 detected subpixel offset (0.0, 1.0) between level 1 and level 3 stack for Fw3\n",
      "For CycD1 detected subpixel offset (0.0, 0.0) between level 1 and level 4 stack for Fw3\n",
      "For CycD1 detected subpixel offset (0.0, 0.0) between level 1 and level 5 stack for Fw3\n",
      "For CycD1 detected subpixel offset (0.0, 0.0) between level 1 and level 6 stack for Fw3\n",
      "For CycE detected subpixel offset (0.0, 0.0) between level 1 and level 2 stack for Fw3\n",
      "For CycE detected subpixel offset (0.0, 0.0) between level 1 and level 3 stack for Fw3\n",
      "For CycE detected subpixel offset (0.0, 0.0) between level 1 and level 4 stack for Fw3\n",
      "For CycE detected subpixel offset (0.0, 0.0) between level 1 and level 5 stack for Fw3\n",
      "For CycE detected subpixel offset (0.0, 0.0) between level 1 and level 6 stack for Fw3\n",
      "For DKK1 detected subpixel offset (0.0, 0.0) between level 1 and level 2 stack for Fw3\n",
      "For DKK1 detected subpixel offset (0.0, 0.0) between level 1 and level 3 stack for Fw3\n",
      "For DKK1 detected subpixel offset (0.0, 0.0) between level 1 and level 4 stack for Fw3\n"
     ]
    }
   ],
   "source": [
    "if not csv_exist:\n",
    "    get_shift_within_cycle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For Concanavadin A detected subpixel offset (-24.0, 7.0) compared to 2seg for Fw1\n",
      "For CycD1 detected subpixel offset (-18.0, -38.0) compared to 2seg for Fw1\n",
      "For CycE detected subpixel offset (-12.0, -6.0) compared to 2seg for Fw1\n",
      "For DKK1 detected subpixel offset (-15.0, 4.0) compared to 2seg for Fw1\n",
      "For Concanavadin A detected subpixel offset (-14.0, -3.0) compared to 2seg for Fw2\n",
      "For CycD1 detected subpixel offset (-8.0, -24.0) compared to 2seg for Fw2\n",
      "For CycE detected subpixel offset (-10.0, -2.0) compared to 2seg for Fw2\n",
      "For DKK1 detected subpixel offset (-7.0, -8.0) compared to 2seg for Fw2\n",
      "For Concanavadin A detected subpixel offset (-26.0, -10.0) compared to 2seg for Fw3\n",
      "For CycD1 detected subpixel offset (0.0, -10.0) compared to 2seg for Fw3\n",
      "For CycE detected subpixel offset (-10.0, -8.0) compared to 2seg for Fw3\n",
      "For DKK1 detected subpixel offset (-15.0, -12.0) compared to 2seg for Fw3\n"
     ]
    }
   ],
   "source": [
    "if not csv_exist:\n",
    "    shift_dict = get_shift_between_cycle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not csv_exist:\n",
    "    shift_crop(df, shift_dict, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine z_stack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maximum_projection(df, img_folder, save=False):\n",
    "    # Read condition and cycles name\n",
    "    conditions = df.Condition.unique()\n",
    "    cycles = df.Cycle.unique()\n",
    "\n",
    "    # Loop through condition and cycle pair\n",
    "    for ele in itertools.product(conditions,cycles):\n",
    "        condition = ele[0]\n",
    "        cycle = ele[1]\n",
    "\n",
    "        # Extract dataset  \n",
    "        df_subset = df[(df.Cycle == cycle) & (df.Condition == condition)] \n",
    "        for marker in df_subset.Marker.unique():\n",
    "            df_channel = df_subset[df_subset.Marker == marker]\n",
    "            imgs = None\n",
    "            for row in df_channel.itertuples():\n",
    "                img = skimage.io.imread(row.Path_corrected)\n",
    "                imgs = np.concatenate((imgs, img[np.newaxis,:,:]), axis = 0) if not (imgs is None) else img[np.newaxis,:,:]\n",
    "\n",
    "            # Save image\n",
    "            img_combined = np.amax(imgs, axis=0, keepdims=True)[0]\n",
    "            filename = '_'.join([row.Condition, 'Combined', row.Cycle, row.Marker])\n",
    "            path = os.path.join(img_folder, filename+'.tiff')\n",
    "            cv2.imwrite(path, img_combined)\n",
    "\n",
    "            # Append dataframe\n",
    "            new_row = {\n",
    "                'Cycle': row.Cycle, \n",
    "                'Condition': row.Condition,\n",
    "                'Z_stack': 'Combined',\n",
    "                'Channel': row.Channel,\n",
    "                'Marker': row.Marker,\n",
    "                'Path': '',\n",
    "                'Path_corrected': path\n",
    "            }\n",
    "\n",
    "\n",
    "            df = df.append(new_row, ignore_index = True)\n",
    "\n",
    "    if save:\n",
    "        df.to_csv(csv_file, index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_maximum_projection(df, data_processed, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect dot in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.feature import blob_log\n",
    "\n",
    "# blobs_log = blob_log(img_corrected, max_sigma=30, num_sigma=10, threshold=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(15, 15))\n",
    "# ax.imshow(img_corrected)\n",
    "# for blob in blobs_log:\n",
    "#     y, x, r =blob\n",
    "#     c = plt.Circle((x, y), r, color='red', linewidth=2, fill=False)\n",
    "#     ax.add_patch(c)\n",
    "#     ax.set_axis_off()\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}